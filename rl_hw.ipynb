{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bac2deac-1e75-4399-aa30-f999cf4233ae",
   "metadata": {},
   "source": [
    "# RL Homework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "29533ba4-f168-4d7b-8967-ee08d38ae8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from tqdm.notebook import tqdm\n",
    "%matplotlib inline\n",
    "%config InlineRenderer.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "126d38a1-05d8-4df7-bc49-b9c23d2388f1",
   "metadata": {},
   "source": [
    "For our RL homework we'll work with another classic control environment: Acrobot. Acrobot consists of a double pendulum where the agent can apply a torque at the joint in the middle.\n",
    "\n",
    "```\n",
    "     o <-- fixed hinge\n",
    "    /\n",
    "   / <-- First rod (can swing aroung the fixed hinge\n",
    "  /\n",
    " o <-- Actuated joint (the agent applies torque here)\n",
    "  \\\n",
    "   \\ <-- Second rod (can swing around the actuated joint)\n",
    "    \\\n",
    "     o <-- free swinging end\n",
    "```\n",
    "\n",
    "The state space for this environment consists of 6 real numbers: the cosine and sine of each of the angle at each joint and the angular velocity at each joint. There are three actions: apply clockwise torque at the actuated joint, apply a counterclockwise torque, or do nothing. The goal of this environment is to swing the free end up to a target height. It gets a reward of -1 at each time step until it reaches the target height, at which point the reward is 0. An episode is truncated after 500 steps. A good total (non-discounted) reward on this environment is around -100.\n",
    "\n",
    "This code for the Acrobot environment is taken from [Gymnasium](https://gymnasium.farama.org/environments/classic_control/acrobot/#starting-state), a library of reinforcement learning environments that are commonly used as a test bed by researchers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7c336f68-7a83-4ab2-a41f-ced8375d6e2a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "class AcrobotEnv:\n",
    "\n",
    "    dt = 0.2\n",
    "\n",
    "    LINK_LENGTH_1 = 1.0  # [m]\n",
    "    LINK_LENGTH_2 = 1.0  # [m]\n",
    "    LINK_MASS_1 = 1.0  #: [kg] mass of link 1\n",
    "    LINK_MASS_2 = 1.0  #: [kg] mass of link 2\n",
    "    LINK_COM_POS_1 = 0.5  #: [m] position of the center of mass of link 1\n",
    "    LINK_COM_POS_2 = 0.5  #: [m] position of the center of mass of link 2\n",
    "    LINK_MOI = 1.0  #: moments of inertia for both links\n",
    "\n",
    "    MAX_VEL_1 = 4 * np.pi\n",
    "    MAX_VEL_2 = 9 * np.pi\n",
    "\n",
    "    AVAIL_TORQUE = [-1.0, 0.0, +1]\n",
    "\n",
    "    torque_noise_max = 0.0\n",
    "\n",
    "    SCREEN_DIM = 500\n",
    "\n",
    "    #: use dynamics equations from the nips paper or the book\n",
    "    book_or_nips = \"book\"\n",
    "    action_arrow = None\n",
    "    domain_fig = None\n",
    "    actions_num = 3\n",
    "\n",
    "    def __init__(self, dense_reward=False):\n",
    "        self.screen = None\n",
    "        self.clock = None\n",
    "        self.isopen = True\n",
    "        high = np.array(\n",
    "            [1.0, 1.0, 1.0, 1.0, self.MAX_VEL_1, self.MAX_VEL_2], dtype=np.float32\n",
    "        )\n",
    "        low = -high\n",
    "        self.state_dim = 6\n",
    "        self.num_actions = 3\n",
    "        self.state = None\n",
    "        self.np_random = np.random.default_rng()\n",
    "        self.dense_reward = dense_reward\n",
    "\n",
    "    def reset(self):\n",
    "        self.state = self.np_random.uniform(low=-0.1, high=0.1, size=(4,)).astype(\n",
    "            np.float32\n",
    "        )\n",
    "        \n",
    "        self.count = 0\n",
    "        return self._get_ob(), {}\n",
    "\n",
    "    def step(self, a):\n",
    "        s = self.state\n",
    "        assert s is not None, \"Call reset before using AcrobotEnv object.\"\n",
    "        torque = self.AVAIL_TORQUE[a]\n",
    "\n",
    "        # Add noise to the force action\n",
    "        if self.torque_noise_max > 0:\n",
    "            torque += self.np_random.uniform(\n",
    "                -self.torque_noise_max, self.torque_noise_max\n",
    "            )\n",
    "\n",
    "        # Now, augment the state with our force action so it can be passed to\n",
    "        # _dsdt\n",
    "        s_augmented = np.append(s, torque)\n",
    "\n",
    "        ns = rk4(self._dsdt, s_augmented, [0, self.dt])\n",
    "\n",
    "        ns[0] = wrap(ns[0], -np.pi, np.pi)\n",
    "        ns[1] = wrap(ns[1], -np.pi, np.pi)\n",
    "        ns[2] = bound(ns[2], -self.MAX_VEL_1, self.MAX_VEL_1)\n",
    "        ns[3] = bound(ns[3], -self.MAX_VEL_2, self.MAX_VEL_2)\n",
    "        self.state = ns\n",
    "        terminated = self._terminal()\n",
    "        reward = -1.0 if not terminated else 0.0\n",
    "        if self.dense_reward:\n",
    "            reward = - np.cos(ns[0]) - np.cos(ns[0] + ns[1]) - 1.0\n",
    "        self.count += 1\n",
    "\n",
    "        return self._get_ob(), reward, terminated, self.count >= 500, {}\n",
    "\n",
    "    def _get_ob(self):\n",
    "        s = self.state\n",
    "        assert s is not None, \"Call reset before using AcrobotEnv object.\"\n",
    "        return np.array(\n",
    "            [np.cos(s[0]), np.sin(s[0]), np.cos(s[1]), np.sin(s[1]), s[2], s[3]], dtype=np.float32\n",
    "        )\n",
    "\n",
    "    def _terminal(self):\n",
    "        s = self.state\n",
    "        assert s is not None, \"Call reset before using AcrobotEnv object.\"\n",
    "        return bool(-np.cos(s[0]) - np.cos(s[1] + s[0]) > 1.0)\n",
    "\n",
    "    def _dsdt(self, s_augmented):\n",
    "        m1 = self.LINK_MASS_1\n",
    "        m2 = self.LINK_MASS_2\n",
    "        l1 = self.LINK_LENGTH_1\n",
    "        lc1 = self.LINK_COM_POS_1\n",
    "        lc2 = self.LINK_COM_POS_2\n",
    "        I1 = self.LINK_MOI\n",
    "        I2 = self.LINK_MOI\n",
    "        g = 9.8\n",
    "        a = s_augmented[-1]\n",
    "        s = s_augmented[:-1]\n",
    "        theta1 = s[0]\n",
    "        theta2 = s[1]\n",
    "        dtheta1 = s[2]\n",
    "        dtheta2 = s[3]\n",
    "        d1 = (\n",
    "            m1 * lc1**2\n",
    "            + m2 * (l1**2 + lc2**2 + 2 * l1 * lc2 * np.cos(theta2))\n",
    "            + I1\n",
    "            + I2\n",
    "        )\n",
    "        d2 = m2 * (lc2**2 + l1 * lc2 * np.cos(theta2)) + I2\n",
    "        phi2 = m2 * lc2 * g * np.cos(theta1 + theta2 - np.pi / 2.0)\n",
    "        phi1 = (\n",
    "            -m2 * l1 * lc2 * dtheta2**2 * np.sin(theta2)\n",
    "            - 2 * m2 * l1 * lc2 * dtheta2 * dtheta1 * np.sin(theta2)\n",
    "            + (m1 * lc1 + m2 * l1) * g * np.cos(theta1 - np.pi / 2)\n",
    "            + phi2\n",
    "        )\n",
    "        if self.book_or_nips == \"nips\":\n",
    "            # the following line is consistent with the description in the\n",
    "            # paper\n",
    "            ddtheta2 = (a + d2 / d1 * phi1 - phi2) / (m2 * lc2**2 + I2 - d2**2 / d1)\n",
    "        else:\n",
    "            # the following line is consistent with the java implementation and the\n",
    "            # book\n",
    "            ddtheta2 = (\n",
    "                a + d2 / d1 * phi1 - m2 * l1 * lc2 * dtheta1**2 * np.sin(theta2) - phi2\n",
    "            ) / (m2 * lc2**2 + I2 - d2**2 / d1)\n",
    "        ddtheta1 = -(d2 * ddtheta2 + phi1) / d1\n",
    "        return dtheta1, dtheta2, ddtheta1, ddtheta2, 0.0\n",
    "\n",
    "\n",
    "def rk4(derivs, y0, t):\n",
    "\n",
    "    try:\n",
    "        Ny = len(y0)\n",
    "    except TypeError:\n",
    "        yout = np.zeros((len(t),), np.float_)\n",
    "    else:\n",
    "        yout = np.zeros((len(t), Ny), np.float_)\n",
    "\n",
    "    yout[0] = y0\n",
    "\n",
    "    for i in np.arange(len(t) - 1):\n",
    "        this = t[i]\n",
    "        dt = t[i + 1] - this\n",
    "        dt2 = dt / 2.0\n",
    "        y0 = yout[i]\n",
    "\n",
    "        k1 = np.asarray(derivs(y0))\n",
    "        k2 = np.asarray(derivs(y0 + dt2 * k1))\n",
    "        k3 = np.asarray(derivs(y0 + dt2 * k2))\n",
    "        k4 = np.asarray(derivs(y0 + dt * k3))\n",
    "        yout[i + 1] = y0 + dt / 6.0 * (k1 + 2 * k2 + 2 * k3 + k4)\n",
    "    # We only care about the final timestep and we cleave off action value which will be zero\n",
    "    return yout[-1][:4]\n",
    "\n",
    "def wrap(x, m, M):\n",
    "    diff = M - m\n",
    "    while x > M:\n",
    "        x = x - diff\n",
    "    while x < m:\n",
    "        x = x + diff\n",
    "    return x\n",
    "\n",
    "def bound(x, m, M=None):\n",
    "    if M is None:\n",
    "        M = m[1]\n",
    "        m = m[0]\n",
    "    # bound x between min (m) and Max (M)\n",
    "    return min(max(x, m), M)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "809f59de-7df4-4dfa-a25a-0a285e43cb2e",
   "metadata": {},
   "source": [
    "As in previous homework assignments, I've broken this down into three sections.\n",
    "\n",
    "NOTE: Reinforcement learning often has pretty high variance, especially for the relatively simple algorithms we've looked at in this class. If your results look like there is some learning happening but it's pretty noisy or if you see rewards going up and then back down again, it may be worth just rerunning training to see what happens. Most likely if you don't get reasonable-looking results in 2-3 runs then something is wrong.\n",
    "\n",
    "## Q Learning (C)\n",
    "\n",
    "The basic version of this homework involves using deep Q learning to control the Acrobot. This is very similar to what we did in class on Monday. For this part of the homework you'll need to set up the `QNetwork` to approximate the Q function and finish the training code below. The `ReplayMemory` class is already complete. Remember that Q learning involves learnign an approximation $\\hat{Q}$ to the optimal Q function according to the temporal difference loss\n",
    "\n",
    "$$\n",
    "L(\\hat{Q}) = \\sum_{(s, a, r, s') \\in D} \\left \\| \\hat{Q}(s, a) - \\left ( r + \\gamma \\max_{a'} \\hat{Q}(s', a') \\right ) \\right \\|\n",
    "$$\n",
    "\n",
    "The way we do exploration in this version is a bit different from what we had in class. There we took three parameters, `eps_start`, `eps_end` and `eps_rate` and we took a random action with a probability that started at `eps_start` and then exponentially decayed toward `eps_end` at a rate controlled by `eps_rate`. For this homework, we'll use a simpler approach called $\\varepsilon$-greedy exploration where we always take a random action with probability $\\varepsilon$ and choose an action from our Q network with probability $(1-\\varepsilon)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "29b718ff-c907-4cd8-8527-668370255140",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QNetwork(nn.Module):\n",
    "\n",
    "    def __init__(self, state_dim, num_actions):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(state_dim, 20),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(20, 20),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(20, num_actions)\n",
    "        )\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        # Run your model on x. This should return a Q value for each action.\n",
    "        return self.model(x)\n",
    "    \n",
    "\n",
    "\n",
    "class ReplayMemory:\n",
    "\n",
    "    def __init__(self, cap, evict_oldest=False):\n",
    "        self.capacity = cap\n",
    "        self.data = []\n",
    "        self.evict_oldest = evict_oldest\n",
    "        if self.evict_oldest:\n",
    "            self.oldest = 0\n",
    "\n",
    "    def push(self, state, action, reward, nstate, term):\n",
    "        if len(self.data) < self.capacity:\n",
    "            self.data.append((state, action, reward, nstate, term))\n",
    "        else:\n",
    "            if self.evict_oldest:\n",
    "                idx = self.oldest\n",
    "                self.oldest = (self.oldest + 1) % self.capacity\n",
    "            else:\n",
    "                idx = random.randint(0, self.capacity - 1)\n",
    "            self.data[idx] = (state, action, reward, nstate, term)\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.data, batch_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def empty(self):\n",
    "        self.data = []\n",
    "        if self.evict_oldest:\n",
    "            self.oldest = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0a97d2db-9684-4cdf-b565-c0e14d9f1205",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block after 'else' statement on line 62 (3532734938.py, line 67)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[30], line 67\u001b[0;36m\u001b[0m\n\u001b[0;31m    pred_next_vals = target_network(nst_batch).max(dim=1).values\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after 'else' statement on line 62\n"
     ]
    }
   ],
   "source": [
    "def train_q_learning(env, gamma=0.99, lr=1e-3, tau=0.05, batch_size=128, num_interactions=10000, eps=0.1, sarsa=False):\n",
    "\n",
    "    policy_network = QNetwork(env.state_dim, env.num_actions)\n",
    "    target_network = QNetwork(env.state_dim, env.num_actions)\n",
    "    target_network.load_state_dict(policy_network.state_dict())\n",
    "\n",
    "    replay_buffer = ReplayMemory(10000)\n",
    "\n",
    "    opt = optim.Adam(policy_network.parameters(), lr=lr)\n",
    "    loss = nn.SmoothL1Loss()\n",
    "\n",
    "    state, _ = env.reset()\n",
    "    ep_r = 0\n",
    "    ep_rewards = []\n",
    "\n",
    "    rng = np.random.default_rng()\n",
    "    for i in tqdm(range(num_interactions)):\n",
    "        \n",
    "        # Choose a random action with probability eps, otherwise take the best\n",
    "        # action according to the policy network.\n",
    "\n",
    "        if rng.random() < eps:\n",
    "            action = rng.integers(0, env.num_actions)\n",
    "\n",
    "        else:\n",
    "            action = policy_network(torch.tensor(state, dtype=torch.float)).argmax()\n",
    "        \n",
    "        \n",
    "        # Take a step in the environment, add the transition to the replay\n",
    "        # buffer, and add the reward to ep_r\n",
    "    \n",
    "        nstate, reward, term, trunc, _ = env.step(action)\n",
    "        replay_buffer.push(state, action, reward, nstate, term)\n",
    "        state = nstate\n",
    "        ep_r += reward\n",
    "        # ep_rewards.append(reward)\n",
    "\n",
    "        if sarsa:\n",
    "            if rng.random() < eps:\n",
    "                    action = rng.integers(0, env.num_actions)\n",
    "            else:\n",
    "                batch = replay_buffer.sample(batch_size)\n",
    "                st_batch, act_batch, r_batch, nst_batch, t_batch = zip(*batch)\n",
    "                st_batch = torch.tensor(np.array(st_batch)).float()\n",
    "                act_batch = torch.tensor(np.array(act_batch)).unsqueeze(dim=1)\n",
    "                r_batch = torch.tensor(np.array(r_batch)).float()\n",
    "                nst_batch = torch.tensor(np.array(nst_batch)).float()\n",
    "                t_batch = torch.tensor(np.array(t_batch))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        else:   \n",
    "\n",
    "\n",
    "            if len(replay_buffer) >= batch_size:\n",
    "                batch = replay_buffer.sample(batch_size)\n",
    "                st_batch, act_batch, r_batch, nst_batch, t_batch = zip(*batch)\n",
    "                st_batch = torch.tensor(np.array(st_batch)).float()\n",
    "                act_batch = torch.tensor(np.array(act_batch)).unsqueeze(dim=1)\n",
    "                r_batch = torch.tensor(np.array(r_batch)).float()\n",
    "                nst_batch = torch.tensor(np.array(nst_batch)).float()\n",
    "                t_batch = torch.tensor(np.array(t_batch))\n",
    "\n",
    "            \n",
    "\n",
    "\n",
    "            # Evaluate the policy network on st_batch and choose Q values\n",
    "            # corresponding to actions in act_batch. These is your predicted\n",
    "            # Q values.\n",
    "            pred_vals = policy_network(st_batch).gather(1, act_batch).squeeze()\n",
    "\n",
    "\n",
    "\n",
    "                else:\n",
    "                    action = policy_network(torch.tensor(state, dtype=torch.float)).argmax()\n",
    "                # get actions with e greedy strat\n",
    "                pred_next_vals = target_network(nst_batch).max(dim=1).values\n",
    "                pred_next_vals[st_batch] = 0\n",
    "                # use this to index into the target q values of nstbatch\n",
    "            \n",
    "            else:\n",
    "\n",
    "                # Evaluate the target network on nst_batch and take the maximum\n",
    "                # over actions. For every element where t_batch is True, set this\n",
    "                # value to zero.\n",
    "                pred_next_vals = target_network(nst_batch).max(dim=1).values\n",
    "                pred_next_vals[t_batch] = 0\n",
    "\n",
    "            # Compute the expected Q value (the right hand side of our loss\n",
    "            # above) using the target network values you just computed and\n",
    "            # r_batch.\n",
    "            expected_q = r_batch + gamma * pred_next_vals\n",
    "\n",
    "            # Apply loss to your predicted Q values and expected Q values, opt step\n",
    "            loss_val = loss(pred_vals, expected_q)\n",
    "            opt.zero_grad()\n",
    "            loss_val.backward()\n",
    "            opt.step()\n",
    "\n",
    "\n",
    "        p_state_dict = policy_network.state_dict()\n",
    "        t_state_dict = target_network.state_dict()\n",
    "        for key in p_state_dict:\n",
    "            t_state_dict[key] = p_state_dict[key] * tau + t_state_dict[key] * (1 - tau)\n",
    "        target_network.load_state_dict(t_state_dict)\n",
    "\n",
    "        if term or trunc:\n",
    "            ep_rewards.append(ep_r)\n",
    "            state, _ = env.reset()\n",
    "            ep_r = 0\n",
    "\n",
    "    return policy_network, ep_rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a8879750-9ffb-44f6-ad16-0584ebf7bad5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d87d58c125604512b9e4f0674f6ec312",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "env = AcrobotEnv()\n",
    "q_policy, q_returns = train_q_learning(env, lr=2e-4, num_interactions=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "65d4cb53-6719-4d16-9ee4-f156b0eadcc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(q_returns)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed998cc-3a41-4976-b185-d8756e36ca12",
   "metadata": {},
   "source": [
    "## SARSA (B)\n",
    "\n",
    "In this section we'll make a slight alteration to the Q learning function above in order to implement SARSA, another classic reinforcement learning algorithm. SARSA is very similar to Q learning except that it uses the _policy_ Q value estimate rather than the _optimal_ Q value estimate. Concretely, this means Q learning uses the update loss\n",
    "\n",
    "$$\n",
    "\\left \\| \\hat{Q}(s, a) - \\left ( r + \\gamma \\max_{a'} \\hat{Q}(s', a') \\right ) \\right \\|\n",
    "$$\n",
    "\n",
    "whereas SARSA first selects an action $a'$ using the same policy we're using for exploration (that is, it uses the $\\epsilon$-greedy scheme) then uses the update rule\n",
    "\n",
    "$$\n",
    "\\left \\| \\hat{Q}(s, a) - \\left ( r + \\gamma \\hat{Q}(s', a') \\right ) \\right \\|\n",
    "$$\n",
    "\n",
    "The difference between the two is only how $a'$ is selected. For SARSA we use the same $\\varepsilon$-greedy policy we use to choose actions to take in the environment, for Q learning we use the true greedy action without any random chance. Modify the Q learning function above so that if the `sarsa` argument is set to true, it uses SARSA and otherwise it uses Q learning. Concretely, this means that rather than taking a maximum over actions on the target Q values of `nst_batch`, you should get a batch of actions using the $\\varepsilon$-greedy strategy and use those actions to index into the target Q values of `nst_batch`. (This is similar to how you use the actions `act_batch` to index into the policy Q values of `st_batch` in Q learning.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5074eb8a-3111-41fa-a879-e9fef2867385",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_policy, s_returns = train_q_learning(env, lr=2e-4, num_interactions=10000, sarsa=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3838e2e4-412c-498f-a6de-766e471f9bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(s_returns)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b0c599-afa8-4e62-bf90-a18e7865f4d0",
   "metadata": {},
   "source": [
    "## Actor-Critic (A)\n",
    "\n",
    "In this section we'll solve the same environment using an actor-critic algorithm rather than Q-learning. For this you'll need to define a policy network and a critic network then fill in the training code below. Actor-critic algorithms come in different flavors, but for this homework we'll optimize the critic $\\hat{V}$ to minimize\n",
    "\n",
    "$$\n",
    "L(\\hat{V}) = \\sum_{(s, a, r, s') \\in D} \\left \\| \\hat{V}(s) - \\left ( r + \\gamma \\hat{V}(s') \\right ) \\right \\|\n",
    "$$\n",
    "\n",
    "and optimize the policy $\\pi$ to maximize\n",
    "\n",
    "$$\n",
    "J(\\pi) = \\sum_{(s, a, r, s') \\in D} \\left ( r + \\gamma \\hat{V}(s') - \\hat{V}(s) \\right ) \\log \\pi(a \\mid s)\n",
    "$$\n",
    "\n",
    "To make things a bit easier, we'll use a single PyTorch optimizer object trained on the loss $\\beta L(\\hat{V}) - J(\\pi)$ where $\\beta$ is a hyperparameter controlling how much relative weight to give the critic loss. You shouldn't need to tune $\\beta$ for this homework.\n",
    "\n",
    "It's also often useful to explicitly encourage exploration by giving the policy a reward based on it's entropy. Mathematically,\n",
    "\n",
    "$$\n",
    "J(\\pi) = \\sum_{(s, a, r, s') \\in D} \\left ( r + \\gamma \\hat{V}(s') - \\hat{V}(s) \\right ) \\log \\pi(a \\mid s) + \\alpha H \\left ( \\pi(\\cdot \\mid s) \\right )\n",
    "$$\n",
    "\n",
    "where $H$ measures entropy. This is optional for this homework but may help you get better performance.\n",
    "\n",
    "In order to make training feasible, you should have your policy network output a PyTorch distribution object (available in `torch.distributions`). Distribution objects have a `.log_prob(a)` method which can tell you the probability of selecting action `a` and an `.entropy()` method which gives you their entropy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d0b581-0831-4c79-89e0-ad153c107618",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Policy(nn.Module):\n",
    "\n",
    "    def __init__(self, state_dim, num_actions):\n",
    "        super().__init__()\n",
    "        # set up self.model. This should be a neural network which outputs\n",
    "        # logits for each action.\n",
    "        pass\n",
    "\n",
    "    def forward(self, x):\n",
    "        logits = self.model(x)\n",
    "        return torch.distributions.Categorical(logits=logits)\n",
    "\n",
    "\n",
    "class Critic(nn.Module):\n",
    "\n",
    "    def __init__(self, state_dim):\n",
    "        super().__init__()\n",
    "        # Set up self.model. This should be a neural network which outputs\n",
    "        # a single number.\n",
    "        pass\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x).squeeze(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b9698fb-4691-47b5-b704-10d8cc9ad217",
   "metadata": {},
   "outputs": [],
   "source": [
    "def actor_critic(env, critic_weight=0.5, entropy_weight=0.2, lr=1e-3, num_interactions=10000, gamma=0.99, update_interval=10):\n",
    "\n",
    "    actor = Policy(env.state_dim, env.num_actions)\n",
    "    critic = Critic(env.state_dim)\n",
    "\n",
    "    opt = optim.Adam(list(actor.parameters()) + list(critic.parameters()), lr=lr)\n",
    "    critic_loss_func = nn.SmoothL1Loss()\n",
    "\n",
    "    replay_buffer = ReplayMemory(update_interval)\n",
    "\n",
    "    state, _ = env.reset()\n",
    "    ep_rew = 0\n",
    "    ep_rewards = []\n",
    "\n",
    "    for step_count in tqdm(range(num_interactions)):\n",
    "        \n",
    "        # Choose an action for the environment. We're no longer using the\n",
    "        # epsilon-greedy approach since our policy is now stochastic. Instead\n",
    "        # you should get a distribution by calling your policy network then use\n",
    "        # the distribution's .sample() method to choose an action.\n",
    "\n",
    "        if (step_count + 1) % update_interval == 0:\n",
    "            batch = replay_buffer.sample(update_interval)\n",
    "            st_batch, act_batch, r_batch, nst_batch, t_batch = zip(*batch)\n",
    "            st_batch = torch.tensor(np.array(st_batch)).float()\n",
    "            act_batch = torch.tensor(np.array(act_batch))\n",
    "            r_batch = torch.tensor(np.array(r_batch)).float()\n",
    "            nst_batch = torch.tensor(np.array(nst_batch)).float()\n",
    "            t_batch = torch.tensor(np.array(t_batch))\n",
    "            replay_buffer.empty()\n",
    "\n",
    "            # Compute the total loss L(V) - J(\\pi).\n",
    "            \n",
    "            # You can use actor(st_batch) to get the policy action distribution\n",
    "            # for each state then call .log_prob(act_batch) on those values to\n",
    "            # get log \\pi(a | s).\n",
    "\n",
    "            # If you want to add entropy weighting, you can call .entropy() on\n",
    "            # the distribution.\n",
    "\n",
    "            # Take a gradient step. Since we put everything together into one\n",
    "            # optimizer, this is just like the gradient steps we've seen before\n",
    "\n",
    "        if term or trunc:\n",
    "            state, _ = env.reset()\n",
    "            ep_rewards.append(ep_rew)\n",
    "            ep_rew = 0\n",
    "\n",
    "    return actor, ep_rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8661c056-38ab-48a4-9baf-3e6290de7a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = AcrobotEnv()\n",
    "ac_policy, ac_returns = actor_critic(env, num_interactions=100000, entropy_weight=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36204f7c-f415-4a02-89d6-66683b4373d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(ac_returns)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca9b597-b33b-4715-a484-1c8df2f2dafe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
